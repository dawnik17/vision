{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c9d228-1934-4870-839f-ecc7af6f61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformer import Decoder, PositionalEncoding, Encoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4521db0-afc9-4ff3-ba92-91a5509a8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40669</th>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96086</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.033881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t_dat  customer_id  article_id     price\n",
       "40669 2018-09-27            0           2  0.033881\n",
       "96086 2018-10-04            0           3  0.033881"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./transaction_sample.csv\")\n",
    "\n",
    "del data[\"sales_channel_id\"]\n",
    "data.head(2)\n",
    "\n",
    "data[\"t_dat\"] = pd.to_datetime(data[\"t_dat\"])\n",
    "data.sort_values(by=[\"customer_id\", \"t_dat\"], ascending=True, inplace=True)\n",
    "\n",
    "entity2idx = lambda data, increment: {item: idx + increment for idx, item in enumerate(data)}\n",
    "idx2entity = lambda entity2idx: {idx: entity for entity, idx in entity2idx.items()}\n",
    "\n",
    "user2idx = entity2idx(data.customer_id.unique(), 0)\n",
    "idx2user = idx2entity(user2idx)\n",
    "\n",
    "pid2idx = entity2idx(data.article_id.unique(), 2)\n",
    "idx2pid = idx2entity(pid2idx)\n",
    "\n",
    "data.customer_id = data.customer_id.map(user2idx)\n",
    "data.article_id = data.article_id.map(pid2idx)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8cacf7-7e6b-4113-be1e-63d51ecae789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[7, 8, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id         article_id\n",
       "0            0             [4, 5]\n",
       "1            0  [7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.groupby([\"customer_id\", \"t_dat\"], sort=False)[\"article_id\"].apply(list).reset_index()\n",
    "train = train[train['article_id'].apply(len) > 1].reset_index(drop=True)\n",
    "\n",
    "del train[\"t_dat\"]\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a88530-f78d-4fba-8c7b-66c51cfe7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_session_len = train['article_id'].apply(len).max() + 1\n",
    "max_session_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a27fbd7-7076-4f69-bfc7-1d3f8eb30ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2idx[\"<PAD>\"] = 0\n",
    "pid2idx[\"<EOS>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6938ff1f-1006-4d02-b608-462b17883c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, data: List, max_session_len: int, pid2idx: Dict):\n",
    "        self.data = data\n",
    "        self.max_session_len = max_session_len\n",
    "        self.pid2idx = pid2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        user = torch.LongTensor([data[0]])\n",
    "        items = torch.LongTensor(data[1][:self.max_session_len-1])\n",
    "\n",
    "        pad = torch.LongTensor([pid2idx[\"<EOS>\"]] + [pid2idx[\"<PAD>\"]] * (self.max_session_len - 1 - len(items)))\n",
    "        return user, torch.cat((items, pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78ad98d-a511-4456-a4cf-772dd9b7f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390619 98406\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "split_ratio = 0.8\n",
    "msk = np.random.rand(len(train)) < split_ratio\n",
    "\n",
    "train_data = train[msk]\n",
    "test_data = train[~msk]\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3d5383-2159-486d-b5d6-dc92af0e23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = CDataset(data=train_data.values.tolist(), max_session_len=max_session_len, pid2idx=pid2idx)\n",
    "test_dataset = CDataset(data=test_data.values.tolist(), max_session_len=max_session_len, pid2idx=pid2idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831d0031-0f8e-4f29-8150-ec160fa823f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]),\n",
       " tensor([ 7,  8,  9, 10, 11,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2999320-80d5-4a70-9dbc-9271c23a8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, number_of_layers, head, dimension, nusers, nitems, max_seq_len, dropout):\n",
    "        super(GPT, self).__init__()\n",
    "        self.users = nn.Embedding(nusers, dimension)\n",
    "        self.items = nn.Embedding(nitems, dimension, padding_idx=0)\n",
    "        self.penc = PositionalEncoding(max_seq_len=max_seq_len, dimension=dimension, dropout=dropout)\n",
    "        \n",
    "        # self.decoder = Decoder(number_of_layers=number_of_layers, head=head, dimension=dimension, dropout=dropout)\n",
    "        self.decoder = Encoder(number_of_layers=number_of_layers, \n",
    "                               head=head, \n",
    "                               dimension=dimension, \n",
    "                               dropout=dropout, \n",
    "                               hidden_dimension=dimension)\n",
    "        self.ffnn = nn.Linear(dimension, nitems)\n",
    "\n",
    "    def forward(self, users, items, mask=None):\n",
    "        \"\"\"\n",
    "        users = [batch, 1]\n",
    "        items = [batch, max_seq_len-1]\n",
    "        \"\"\"\n",
    "        # batch, dimension\n",
    "        users = self.users(users)\n",
    "\n",
    "        # batch, max_seq_len, dimension\n",
    "        items = self.items(items)\n",
    "        \n",
    "        # user item session\n",
    "        input_vec = torch.cat((users, items), dim=1)\n",
    "        input_vec = self.penc(input_vec)\n",
    "        \n",
    "        # output = self.decoder(input_vec=input_vec, \n",
    "        #                       encoder_output=input_vec, \n",
    "        #                       encmask=mask, \n",
    "        #                       decmask=mask)\n",
    "        output = self.decoder(input_vec=input_vec, mask=mask)\n",
    "        # return self.ffnn(output)\n",
    "        return  F.log_softmax(self.ffnn(output), dim=-1)\n",
    "\n",
    "def init_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6feca4e2-d2ae-4cba-a964-cb7c5cae06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, users, items, device, pad_idx=0):\n",
    "        \"\"\"\n",
    "        users = [batch]\n",
    "        items = [batch, max_session_length+1] i.e. [item1, item2, item3, <EOS>]\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.pad_idx = pad_idx\n",
    "        self.target = items\n",
    "        self.ntokens = (self.target != pad_idx).data.sum()\n",
    "        \n",
    "        self.item_model_input = items[:, :-1]\n",
    "        self.user_model_input = users\n",
    "\n",
    "        self.mask = self.mask().to(device)\n",
    "\n",
    "    def mask(self):\n",
    "        # <PAD> Mask for decoder\n",
    "        trg_pad_mask = (self.item_model_input != self.pad_idx)\n",
    "        trg_pad_mask = torch.cat((torch.ones((trg_pad_mask.size(0), 1), dtype=torch.long, device=self.device), trg_pad_mask), dim=1)\n",
    "        trg_pad_mask = trg_pad_mask.unsqueeze(1)\n",
    "\n",
    "        # Future Masking\n",
    "        dimension = self.item_model_input.size(-1) + 1\n",
    "        future_mask = torch.tril(torch.ones(1, dimension, dimension)).to(self.device)\n",
    "        future_mask[future_mask != 0] = 1\n",
    "        future_mask = Variable(future_mask > 0)\n",
    "\n",
    "        # Final Decoder Mask\n",
    "        # \"AND\" condition on <PAD> Mask and Future Mask\n",
    "        return trg_pad_mask & future_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b4d96c5-af21-4420-b058-4268f76e5e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 heads 128 dimension in MultiHeadedAttention\n",
      "8 heads 128 dimension in MultiHeadedAttention\n",
      "8 heads 128 dimension in MultiHeadedAttention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (users): Embedding(150208, 128)\n",
       "  (items): Embedding(61544, 128, padding_idx=0)\n",
       "  (penc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Encoder(\n",
       "    (enclays): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffnn): FeedForwardNet(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (resconn1): ResidualConnection(\n",
       "          (norm): LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (resconn2): ResidualConnection(\n",
       "          (norm): LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (ffnn): Linear(in_features=128, out_features=61544, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_seq_len = max_session_length + 1 (for user emb)\n",
    "device = torch.device(\"mps\")\n",
    "number_of_layers = 3\n",
    "head = 8\n",
    "dimension = 128\n",
    "nusers = len(user2idx)\n",
    "nitems = len(pid2idx)\n",
    "max_seq_len = max_session_len\n",
    "dropout = 0.1\n",
    "\n",
    "model = GPT(number_of_layers=number_of_layers,\n",
    "            head=head,\n",
    "            dimension=dimension,\n",
    "            nusers=nusers,\n",
    "            nitems=nitems,\n",
    "            max_seq_len=max_seq_len,\n",
    "            dropout=dropout).to(device)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ca9d9d-a7e9-482f-9865-c81729e69b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion(nn.Module):\n",
    "    def __init__(self, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        \n",
    "    def forward(self, prediction, target):\n",
    "        prediction = prediction.contiguous().view(-1, prediction.size(-1))\n",
    "        target = target.contiguous().view(-1)\n",
    "        \n",
    "        one_hot_target = torch.nn.functional.one_hot(\n",
    "            target, num_classes=prediction.size(-1)\n",
    "        ).float()\n",
    "        one_hot_target[:, self.pad_idx] = 0.\n",
    "        return self.criterion(prediction, one_hot_target)\n",
    "\n",
    "# class Criterion(nn.Module):\n",
    "#     def __init__(self, vocab_size, pad_index, alpha):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.pad_index = pad_index\n",
    "\n",
    "#     def forward(self, prediction, target):\n",
    "#         prediction = prediction.contiguous().view(-1, prediction.size(-1))\n",
    "#         target = target.contiguous().view(-1)\n",
    "\n",
    "#         one_hot_target = torch.nn.functional.one_hot(target, num_classes=prediction.size(-1))\n",
    "#         one_hot_target[:, self.pad_index] = 0\n",
    "#         one_hot_target = (one_hot_target * (1 - self.alpha)) + (\n",
    "#             self.alpha / (self.vocab_size - 2)\n",
    "#         )\n",
    "#         one_hot_target.masked_fill_((target == self.pad_index).unsqueeze(1), 0)\n",
    "\n",
    "#         return F.kl_div(prediction, one_hot_target, reduction=\"sum\")\n",
    "\n",
    "\n",
    "class CustomAdam:\n",
    "    def __init__(self, dimension, optimizer, warmup_steps=4000, step_num=0):\n",
    "        self.optimizer = optimizer\n",
    "        self.step_num = step_num\n",
    "        self.dimension = dimension\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        lr = self.rate()\n",
    "\n",
    "        for pg in self.optimizer.param_groups:\n",
    "            pg[\"lr\"] = lr\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self):\n",
    "        return self.dimension ** (-0.5) * min(\n",
    "            self.step_num ** (-0.5), self.step_num * self.warmup_steps ** (-1.5)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7be4450-af00-4401-a3ba-36f1b26d98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "criterion = Criterion()# (vocab_size=nitems, pad_index=0, alpha=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ae1fcf-8744-4cf8-a49c-653844d96692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = torch.optim.Adam(\n",
    "#             model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9\n",
    "#         )\n",
    "\n",
    "# optimizer = CustomAdam(\n",
    "#         dimension=512,\n",
    "#         warmup_steps=400,\n",
    "#         optimizer=optim,\n",
    "#         step_num=0,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6ec359-ccce-4a85-8633-aead52a859ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, device, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    running_accuracy = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader)\n",
    "\n",
    "    for minibatch, (users, items) in enumerate(pbar):\n",
    "        users = users.to(device)\n",
    "        items = items.to(device)\n",
    "\n",
    "        batch = Batch(users, items, device, pad_idx=0)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch.user_model_input, batch.item_model_input, batch.mask)\n",
    "        loss = criterion(output, batch.target) / batch.ntokens\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.detach().item()\n",
    "        # total_tokens += batch.ntokens\n",
    "\n",
    "        pred = output.argmax(-1)\n",
    "        labels = batch.target\n",
    "\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        processed += torch.count_nonzero(labels).item()\n",
    "        running_accuracy += round((correct / processed) * 100, 14)\n",
    "        \n",
    "        pbar.set_description(f\"Train Epoch: {epoch} Loss: {loss}, Accuracy: {round((correct / processed) * 100, 14)}\")\n",
    "\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84e5a486-6f47-4565-ad0e-386e0873f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, criterion, device, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader)\n",
    "\n",
    "    for minibatch, (users, items) in enumerate(pbar):\n",
    "        users = users.to(device)\n",
    "        items = items.to(device)\n",
    "\n",
    "        batch = Batch(users, items, device, pad_idx=0)\n",
    "        output = model(batch.user_model_input, batch.item_model_input, batch.mask)\n",
    "        \n",
    "        # output = output.contiguous().view(-1, output.size(-1))\n",
    "        loss = criterion(output, batch.target)\n",
    "\n",
    "        total_loss += loss.detach().item()\n",
    "        total_tokens += batch.ntokens\n",
    "        pbar.set_description(f\"Test Epoch: {epoch} Loss: {total_loss / total_tokens}\")\n",
    "\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e102789-5b13-4141-a0b7-e1b61978c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/6104 [00:00<?, ?it/s]/var/folders/gr/zw47r5vs48j4tst50wq4qr840000gn/T/ipykernel_13383/3154967200.py:33: UserWarning: MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:144.)\n",
      "  processed += torch.count_nonzero(labels).item()\n",
      "Train Epoch: 0 Loss: 85.95155334472656, Accuracy: 12.56801917659615:   3%| | 169/6104 [02:04<1:12:07"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch, model, optimizer, criterion, device, train_loader)\n",
    "    test(epoch, model, criterion, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
